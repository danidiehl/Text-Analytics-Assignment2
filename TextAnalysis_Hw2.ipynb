{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics Group Assignment2\n",
    "Due: September 25, 2017, by 11:59 p.m. In this assignment you are an analytics consultant to a   (i) brand manager, (ii) product manager and (iii)advertising manager. Your job is    to give advice/insights to these individuals based on the analysis of social media conversations. The detailed tasks are described below. We use cars as an example of a “high involvement” good (recall from class discussions that for high involvement goods, people use social media heavily for awareness building and research).\n",
    "\n",
    "1.Develop a   crawler/scraper to fetch messages posted in Edmunds.com discussion forums. The crawler output should be a .csv file with the following columns: date, userid, and message (even though you will only use the messages in your analysis). Before you develop the crawler, carefully study one of the forums on Edmunds.com to understand the html as well as the threading structures.\n",
    "\n",
    "2.Fetch between 5,000 and 10,000 posts about cars from a General topics forum. Do NOT choosea forum dedicated to a   particular brand or model. Instead, you can choose the General & Sedans categories and then select, for example, the Entry Level Luxury forum https://forums.edmunds.com/discussion/2864/general/x/entry-level-luxury-performance-sedansThe idea is    to have multiple brands and models being discussed without one of them being the focal point.\n",
    "\n",
    "3.Once you fetch the data, find the top 10 brands from frequency counts. You will need to write a script to count the frequencies. Be sure not to count a mention more than once per post, evenif   it    is mentioned multiple times.Replace modelswith brands so that from now on you have to deal with only brands and not models. You will need another script for this job. This step is meant to help simplify the analysis. A    list of model and brand names (not exhaustive) are provided in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task A:\n",
    "Identify top 10 brands by frequency. From the posts, calculate lift ratios for associations between the brands. You will have to write a   script to do this task). Show the brands on a   multi-dimensional scaling (MDS) map (use a Python script for MDS, there are multiple scripts available onthe Internet). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>message</th>\n",
       "      <th>userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>March 23, 2002  7:04PM</td>\n",
       "      <td>entry level performance luxury sedans are a ho...</td>\n",
       "      <td>cybersol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>March 25, 2002  5:54AM</td>\n",
       "      <td>i personally think that with a few tweaks the ...</td>\n",
       "      <td>merc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>March 25, 2002  7:06AM</td>\n",
       "      <td>i am debating a new purchase and these two are...</td>\n",
       "      <td>fredvh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                    date  \\\n",
       "0         0.0  March 23, 2002  7:04PM   \n",
       "1         1.0  March 25, 2002  5:54AM   \n",
       "2         2.0  March 25, 2002  7:06AM   \n",
       "\n",
       "                                             message    userid  \n",
       "0  entry level performance luxury sedans are a ho...  cybersol  \n",
       "1  i personally think that with a few tweaks the ...     merc1  \n",
       "2  i am debating a new purchase and these two are...    fredvh  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#car forum data\n",
    "forum_data =pd.read_csv('reed_new_out.csv', header = 0)\n",
    "\n",
    "df2=pd.DataFrame([['April 12, 2002 2:53PM','dani','bmw toyota pontiac honda acura audi nissan infiniti ford subaru']], columns=['date','userid','message'])\n",
    "forum_data=forum_data.append(df2)\n",
    "forum_data['message']=forum_data['message'].str.lower()\n",
    "forum_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#list of car brands/names\n",
    "model_list =pd.read_csv('Cars make model list3.csv', header = 2)\n",
    "model_list['Search']=model_list['Search'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##some of the Search values from the model_list df have a weird format after that we need to remove\n",
    "#'legend\\xca'.replace('\\xca','')\n",
    "model_list['Search'].replace('\\xca','').values\n",
    "ls=model_list['Search'].tolist()\n",
    "\n",
    "for i in range(len(ls)):\n",
    "    ls[i]=ls[i].replace('\\xca','')\n",
    "\n",
    "ls                              #the correct names now! add this back to model_list df\n",
    "model_list['Search1']=ls        #setting new column equal to correct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_model(s):\n",
    "    for model in model_list['Search1'].values:\n",
    "        if model in s:\n",
    "            s=s.replace(model,model_list[model_list['Search1']==model]['Replace'].values[0])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>message</th>\n",
       "      <th>userid</th>\n",
       "      <th>message_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>March 23, 2002  7:04PM</td>\n",
       "      <td>entry level performance luxury sedans are a ho...</td>\n",
       "      <td>cybersol</td>\n",
       "      <td>entry level performance luxury sedans are a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>March 25, 2002  5:54AM</td>\n",
       "      <td>i personally think that with a few tweaks the ...</td>\n",
       "      <td>merc1</td>\n",
       "      <td>i personally think that with a few tweaks the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>March 25, 2002  7:06AM</td>\n",
       "      <td>i am debating a new purchase and these two are...</td>\n",
       "      <td>fredvh</td>\n",
       "      <td>i am debating a new purchase and these two are...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                    date  \\\n",
       "0         0.0  March 23, 2002  7:04PM   \n",
       "1         1.0  March 25, 2002  5:54AM   \n",
       "2         2.0  March 25, 2002  7:06AM   \n",
       "\n",
       "                                             message    userid  \\\n",
       "0  entry level performance luxury sedans are a ho...  cybersol   \n",
       "1  i personally think that with a few tweaks the ...     merc1   \n",
       "2  i am debating a new purchase and these two are...    fredvh   \n",
       "\n",
       "                                       message_clean  \n",
       "0  entry level performance luxury sedans are a ho...  \n",
       "1  i personally think that with a few tweaks the ...  \n",
       "2  i am debating a new purchase and these two are...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapping that function to forum df\n",
    "forum_data['message_clean']=forum_data['message'].astype(str).map(replace_model)\n",
    "forum_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#removing stopwords and adding to new column in df\n",
    "stop = stopwords.words('english')\n",
    "forum_data['message_without_stopwords'] = forum_data['message_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acura': 675,\n",
       " 'audi': 594,\n",
       " 'bmw': 1866,\n",
       " 'buick': 52,\n",
       " 'cadillac': 133,\n",
       " 'chevrolet': 173,\n",
       " 'chrysler': 101,\n",
       " 'dodge': 241,\n",
       " 'ford': 296,\n",
       " 'honda': 683,\n",
       " 'hyundai': 247,\n",
       " 'infiniti': 506,\n",
       " 'kia': 29,\n",
       " 'lincoln': 74,\n",
       " 'mazda': 118,\n",
       " 'mercedes': 265,\n",
       " 'mercury': 8,\n",
       " 'mitsubishi': 27,\n",
       " 'nissan': 562,\n",
       " 'pontiac': 1088,\n",
       " 'saturn': 33,\n",
       " 'subaru': 277,\n",
       " 'suzuki': 25,\n",
       " 'toyota': 1654,\n",
       " 'volkswagen': 236,\n",
       " 'volvo': 156}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count the number of messages that contain each brand name\n",
    "#careful- don't want to count same message twice if brand is stated twice\n",
    "\n",
    "counter={}\n",
    "for brand in model_list['Replace'].drop_duplicates():\n",
    "    if len(forum_data['message_without_stopwords'].str.contains(brand).value_counts().values)>1:\n",
    "        count=forum_data['message_without_stopwords'].str.contains(brand).value_counts()[True]\n",
    "    else:\n",
    "        count=0\n",
    "    counter[brand]=count\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bmw', 1866],\n",
       " ['toyota', 1654],\n",
       " ['pontiac', 1088],\n",
       " ['honda', 683],\n",
       " ['acura', 675],\n",
       " ['audi', 594],\n",
       " ['nissan', 562],\n",
       " ['infiniti', 506],\n",
       " ['ford', 296],\n",
       " ['subaru', 277]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counterlist=[] #list of [brand, #messages brand appears in]\n",
    "for key, value in counter.iteritems():\n",
    "    temp = [key,value]\n",
    "    counterlist.append(temp)\n",
    "\n",
    "top10=sorted(counterlist, key=lambda x: x[1],reverse=True)[:10]\n",
    "top10 #list of top 10 [brand, #messages] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bmw',\n",
       " 'toyota',\n",
       " 'pontiac',\n",
       " 'honda',\n",
       " 'acura',\n",
       " 'audi',\n",
       " 'nissan',\n",
       " 'infiniti',\n",
       " 'ford',\n",
       " 'subaru']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dictionary of top 10 to values and list of top 10 brands\n",
    "num={}  #dictionary of top 10 {'brand':#messages}\n",
    "for i in top10:\n",
    "    num[i[0]]=i[1]\n",
    "num\n",
    "\n",
    "listof10=[]   \n",
    "for i in top10:\n",
    "    listof10.append(i[0])\n",
    "listof10   #list of only brand names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bmw', 'toyota'), ('bmw', 'pontiac'), ('bmw', 'honda'), ('bmw', 'acura'), ('bmw', 'audi'), ('bmw', 'nissan'), ('bmw', 'infiniti'), ('bmw', 'ford'), ('bmw', 'subaru'), ('toyota', 'pontiac'), ('toyota', 'honda'), ('toyota', 'acura'), ('toyota', 'audi'), ('toyota', 'nissan'), ('toyota', 'infiniti'), ('toyota', 'ford'), ('toyota', 'subaru'), ('pontiac', 'honda'), ('pontiac', 'acura'), ('pontiac', 'audi'), ('pontiac', 'nissan'), ('pontiac', 'infiniti'), ('pontiac', 'ford'), ('pontiac', 'subaru'), ('honda', 'acura'), ('honda', 'audi'), ('honda', 'nissan'), ('honda', 'infiniti'), ('honda', 'ford'), ('honda', 'subaru'), ('acura', 'audi'), ('acura', 'nissan'), ('acura', 'infiniti'), ('acura', 'ford'), ('acura', 'subaru'), ('audi', 'nissan'), ('audi', 'infiniti'), ('audi', 'ford'), ('audi', 'subaru'), ('nissan', 'infiniti'), ('nissan', 'ford'), ('nissan', 'subaru'), ('infiniti', 'ford'), ('infiniti', 'subaru'), ('ford', 'subaru')]\n"
     ]
    }
   ],
   "source": [
    "#getting combinations of top 10 brand names, naming the list of (brand1, brand2) as comb\n",
    "import itertools\n",
    "print list(itertools.combinations(listof10,2))\n",
    "comb=list(itertools.combinations(listof10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('acura', 'audi'): 148,\n",
       " ('acura', 'ford'): 57,\n",
       " ('acura', 'infiniti'): 178,\n",
       " ('acura', 'nissan'): 123,\n",
       " ('acura', 'subaru'): 61,\n",
       " ('audi', 'ford'): 55,\n",
       " ('audi', 'infiniti'): 132,\n",
       " ('audi', 'nissan'): 86,\n",
       " ('audi', 'subaru'): 51,\n",
       " ('bmw', 'acura'): 310,\n",
       " ('bmw', 'audi'): 316,\n",
       " ('bmw', 'ford'): 137,\n",
       " ('bmw', 'honda'): 279,\n",
       " ('bmw', 'infiniti'): 310,\n",
       " ('bmw', 'nissan'): 216,\n",
       " ('bmw', 'pontiac'): 499,\n",
       " ('bmw', 'subaru'): 106,\n",
       " ('bmw', 'toyota'): 687,\n",
       " ('ford', 'subaru'): 26,\n",
       " ('honda', 'acura'): 193,\n",
       " ('honda', 'audi'): 95,\n",
       " ('honda', 'ford'): 72,\n",
       " ('honda', 'infiniti'): 87,\n",
       " ('honda', 'nissan'): 161,\n",
       " ('honda', 'subaru'): 45,\n",
       " ('infiniti', 'ford'): 40,\n",
       " ('infiniti', 'subaru'): 44,\n",
       " ('nissan', 'ford'): 57,\n",
       " ('nissan', 'infiniti'): 108,\n",
       " ('nissan', 'subaru'): 41,\n",
       " ('pontiac', 'acura'): 210,\n",
       " ('pontiac', 'audi'): 171,\n",
       " ('pontiac', 'ford'): 59,\n",
       " ('pontiac', 'honda'): 189,\n",
       " ('pontiac', 'infiniti'): 267,\n",
       " ('pontiac', 'nissan'): 181,\n",
       " ('pontiac', 'subaru'): 72,\n",
       " ('toyota', 'acura'): 269,\n",
       " ('toyota', 'audi'): 238,\n",
       " ('toyota', 'ford'): 128,\n",
       " ('toyota', 'honda'): 333,\n",
       " ('toyota', 'infiniti'): 192,\n",
       " ('toyota', 'nissan'): 243,\n",
       " ('toyota', 'pontiac'): 398,\n",
       " ('toyota', 'subaru'): 102}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting how many messages contain each combination of brands\n",
    "#counter_comb={(brand1, brand2):num of messages}\n",
    "\n",
    "counter_comb={}\n",
    "for brand in comb:\n",
    "    mask_b0=(forum_data['message_without_stopwords'].str.contains(brand[0]))\n",
    "    mask_b1=(forum_data['message_without_stopwords'].str.contains(brand[1]))\n",
    "    mask=(mask_b0 & mask_b1)\n",
    "    count=len(forum_data['message_without_stopwords'][mask])\n",
    "    counter_comb[brand]=count\n",
    "counter_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('acura', 'audi'): 2.1309489961341814,\n",
       " ('acura', 'ford'): 1.646951951951952,\n",
       " ('acura', 'infiniti'): 3.0086195286195285,\n",
       " ('acura', 'nissan'): 1.871830763147489,\n",
       " ('acura', 'subaru'): 1.8834229175023398,\n",
       " ('audi', 'ford'): 1.8058683683683683,\n",
       " ('audi', 'infiniti'): 2.5353535353535355,\n",
       " ('audi', 'nissan'): 1.4872269551984854,\n",
       " ('audi', 'subaru'): 1.7893921161069175,\n",
       " ('bmw', 'acura'): 1.4208487158112024,\n",
       " ('bmw', 'audi'): 1.6458511517461143,\n",
       " ('bmw', 'ford'): 1.4319200631499667,\n",
       " ('bmw', 'honda'): 1.2637856440048396,\n",
       " ('bmw', 'infiniti'): 1.8954009548864854,\n",
       " ('bmw', 'nissan'): 1.1890698126809396,\n",
       " ('bmw', 'pontiac'): 1.4189319518000125,\n",
       " ('bmw', 'subaru'): 1.1839027089355016,\n",
       " ('bmw', 'toyota'): 1.2850237366687791,\n",
       " ('ford', 'subaru'): 1.8306420138550104,\n",
       " ('honda', 'acura'): 2.4167648175261647,\n",
       " ('honda', 'audi'): 1.351817343764635,\n",
       " ('honda', 'ford'): 2.0559930354952316,\n",
       " ('honda', 'infiniti'): 1.4532809796352988,\n",
       " ('honda', 'nissan'): 2.4214216117922294,\n",
       " ('honda', 'subaru'): 1.3731361428397757,\n",
       " ('infiniti', 'ford'): 1.5417690417690417,\n",
       " ('infiniti', 'subaru'): 1.812274368231047,\n",
       " ('nissan', 'ford'): 1.9781006540348178,\n",
       " ('nissan', 'infiniti'): 2.192494338401812,\n",
       " ('nissan', 'subaru'): 1.5204401505710652,\n",
       " ('pontiac', 'acura'): 1.6507761437908497,\n",
       " ('pontiac', 'audi'): 1.5275038992869876,\n",
       " ('pontiac', 'ford'): 1.057628055445151,\n",
       " ('pontiac', 'honda'): 1.4682964968564292,\n",
       " ('pontiac', 'infiniti'): 2.799841243315508,\n",
       " ('pontiac', 'nissan'): 1.708893199183588,\n",
       " ('pontiac', 'subaru'): 1.3791940964111276,\n",
       " ('toyota', 'acura'): 1.3909597384567154,\n",
       " ('toyota', 'audi'): 1.39848098070589,\n",
       " ('toyota', 'ford'): 1.5093303702735383,\n",
       " ('toyota', 'honda'): 1.7017257954008296,\n",
       " ('toyota', 'infiniti'): 1.3243926569198636,\n",
       " ('toyota', 'nissan'): 1.5091625176967731,\n",
       " ('toyota', 'pontiac'): 1.2767922238423786,\n",
       " ('toyota', 'subaru'): 1.2852465743258876}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate lift for associations between the top 10 brands\n",
    "#lift=number of messages*num messages with a and b / (num messages with a) * (num messages with b)\n",
    "\n",
    "def lift(a,b):\n",
    "    num=len(forum_data)\n",
    "    num_a_and_b=counter_comb[(a,b)]\n",
    "    num_a=float(counter[a])\n",
    "    num_b=float(counter[b])\n",
    "    lift_val=(num*num_a_and_b)/(num_a*num_b)\n",
    "    return lift_val\n",
    "\n",
    "lift_ratios={} \n",
    "for brands in comb:\n",
    "    #print brands\n",
    "    lift_val=lift(brands[0],brands[1])\n",
    "    lift_ratios[brands]=lift_val\n",
    "lift_ratios  #dictionary of {(brand1, brand2):lift value}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task B:\n",
    "What insights can you offer brand managers from your analysis in Task A    (choose two brands that you can offer the most interesting/useful insights for)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task C:\n",
    "What are 5   most frequently mentioned attributes of cars in the discussions? Note that the same attribute may be described by different words –   e.g., pick-up and acceleration may both referto a more general attribute, “performance”. You have to make suitable replacements. Now pick the 5 most frequently mentioned brands. Which attributes are most strongly associated with which of these 5   brands? You DON’T have to do a sentiment analysis for this assignment.\n",
    "While BMW has claimed that they are the “ultimate driving machine”, is    that how people feel on Edmunds? Show your analysis.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task D:\n",
    "What advice will you give to a (i) product manager, and (ii) marketing/advertising manager of these brands based on your analysis in Task C? For this assignment, you can assume the sentiment (e.g., that it   is    positive). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task E:\n",
    "Which is the most aspirational brand in your data in terms of people actually wanting to buy or own? Describe your analysis. What are the business implications for this brand? Provide the following details in your write-up (I    am not setting a   strict page limit, but 3-4 pages, single-spaced, 11 font size should be enough with screenshots)\n",
    "\n",
    "1.Which forum you chose (provide URL) \n",
    "\n",
    "2.Which 10 brands you chose –   provide the frequency table\n",
    "\n",
    "3.Show all lift calculations in a   table.\n",
    "\n",
    "4.Show the MDS map (put screenshots in your report)\n",
    "\n",
    "5.State the 5   attributes you chose (again, a   table is    good here). \n",
    "\n",
    "6.For task E, provide all details of your analysis –   e.g., how you measured “aspirational” and howyou found the most aspirational brand.\n",
    "\n",
    "7.Advice/insights based on your analysis for brand, product and advertising managers. Your submission should include all scripts as well as your answers to the questions above (generally speaking, I  won’t run these scripts, but if   the numbers don’t look right, I may run some of them). Also include the final data file after all replacements of models and attributes have been done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
